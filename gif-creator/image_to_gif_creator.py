import torch
import numpy as np
import gradio as gr
import os
from glob import glob
from pathlib import Path
from typing import Optional
import random
from PIL import Image
from moviepy import VideoFileClip
from diffusers import DiffusionPipeline
from diffusers.utils import export_to_video
from diffusers import FluxPipeline
from google import genai
from io import BytesIO
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Environment variables
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')  # Support both, prefer GEMINI_API_KEY
MODEL_CHOICE = os.getenv('MODEL_CHOICE', 'gemini')  # Default to gemini

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-video-diffusion-img2vid-xt")
pipe.to(device)

# Initialize Gemini client if API key is available
gemini_client = None
if GEMINI_API_KEY:
    gemini_client = genai.Client(api_key=GEMINI_API_KEY)

max_64_bit_int = 2**63 - 1

def generate_image_with_gemini(prompt):
    """Generate image using Gemini 2.5 Flash Image"""
    if not gemini_client:
        raise ValueError("Gemini client not initialized. Please set GEMINI_API_KEY environment variable.")
    
    try:
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash-image-preview",
            contents=[prompt],
        )
        
        for part in response.candidates[0].content.parts:
            if part.inline_data is not None:
                image = Image.open(BytesIO(part.inline_data.data))
                return image
        
        raise ValueError("No image generated by Gemini")
    except Exception as e:
        if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
            raise ValueError(f"Gemini API quota exceeded: {str(e)}")
        else:
            raise ValueError(f"Gemini image generation failed: {str(e)}")

def generate_image_with_flux(prompt, num_inference_steps, guidance_scale, seed):
    """Generate image using FLUX.1-dev"""
    try:
        text_to_img_pipe = FluxPipeline.from_pretrained("black-forest-labs/FLUX.1-dev", torch_dtype=torch.bfloat16)
        text_to_img_pipe.enable_model_cpu_offload()

        generated_image = text_to_img_pipe(
            prompt=prompt,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            generator=torch.Generator(device).manual_seed(seed)
        ).images[0]
        
        return generated_image
    except Exception as e:
        if "GatedRepoError" in str(e) or "403" in str(e):
            raise ValueError("FLUX.1-dev requires HuggingFace login. Please run 'huggingface-cli login' or use 'uv run huggingface-cli login'")
        else:
            raise ValueError(f"FLUX image generation failed: {str(e)}")

def generateGif(prompt, num_inference_steps, guidance_scale, seed, model_choice=None):
    # Determine which model to use
    if model_choice is None:
        model_choice = MODEL_CHOICE
    
    generated_image = None
    last_error = None
    
    # Try primary model
    try:
        if model_choice == 'gemini' and gemini_client:
            print(f"Attempting to generate image with Gemini...")
            generated_image = generate_image_with_gemini(prompt)
        else:
            print(f"Attempting to generate image with FLUX...")
            generated_image = generate_image_with_flux(prompt, num_inference_steps, guidance_scale, seed)
    except Exception as e:
        print(f"Primary model ({model_choice}) failed: {e}")
        last_error = e
        
        # Try fallback model
        try:
            if model_choice == 'gemini':
                print("Falling back to FLUX model...")
                generated_image = generate_image_with_flux(prompt, num_inference_steps, guidance_scale, seed)
            else:
                print("Falling back to Gemini model...")
                if gemini_client:
                    generated_image = generate_image_with_gemini(prompt)
                else:
                    raise ValueError("Gemini fallback not available - no API key set")
        except Exception as fallback_error:
            print(f"Fallback model also failed: {fallback_error}")
            raise ValueError(f"Both models failed. Primary: {last_error}. Fallback: {fallback_error}")
    
    if generated_image is None:
        raise ValueError("Failed to generate image with any available model")

    os.makedirs("outputs", exist_ok=True)

    generated_image.save("outputs/generated_image.png")
    resized_image = resize_image(generated_image)
    video_path = generateVideo(resized_image)

    gif_path = convertVideoToGif()
    return gif_path

def generateVideo(
    image: Image,
    seed: Optional[int] = 42,
    randomize_seed: bool = True,
    motion_bucket_id: int = 127,
    fps_id: int = 6,
    version: str = "svd_xt",
    cond_aug: float = 0.02,
    decoding_t: int = 3,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.
    device: str = "cuda",
    output_folder: str = "outputs",
    progress=gr.Progress(track_tqdm=True)
):
    if image.mode == "RGBA":
        image = image.convert("RGB")
        
    if(randomize_seed):
        seed = random.randint(0, max_64_bit_int)
    generator = torch.manual_seed(seed)
    
    os.makedirs(output_folder, exist_ok=True)
    video_path = os.path.join(output_folder, "generated_video.mp4")

    frames = pipe(image, decode_chunk_size=decoding_t, generator=generator, motion_bucket_id=motion_bucket_id, noise_aug_strength=0.1, num_frames=25).frames[0]
    export_to_video(frames, video_path, fps=fps_id)
    torch.manual_seed(seed)

def convertVideoToGif():
    video_path = "outputs/generated_video.mp4"
    videoClip = VideoFileClip(video_path)
    gif_path = "outputs/generated_gif.gif"
    videoClip.write_gif(gif_path)
    return gif_path

def resize_image(image, output_size=(1024, 576)):
    # Calculate aspect ratios
    target_aspect = output_size[0] / output_size[1]  # Aspect ratio of the desired size
    image_aspect = image.width / image.height  # Aspect ratio of the original image

    # Resize then crop if the original image is larger
    if image_aspect > target_aspect:
        # Resize the image to match the target height, maintaining aspect ratio
        new_height = output_size[1]
        new_width = int(new_height * image_aspect)
        resized_image = image.resize((new_width, new_height), Image.LANCZOS)
        # Calculate coordinates for cropping
        left = (new_width - output_size[0]) / 2
        top = 0
        right = (new_width + output_size[0]) / 2
        bottom = output_size[1]
    else:
        # Resize the image to match the target width, maintaining aspect ratio
        new_width = output_size[0]
        new_height = int(new_width / image_aspect)
        resized_image = image.resize((new_width, new_height), Image.LANCZOS)
        # Calculate coordinates for cropping
        left = 0
        top = (new_height - output_size[1]) / 2
        right = output_size[0]
        bottom = (new_height + output_size[1]) / 2

    # Crop the image
    cropped_image = resized_image.crop((left, top, right, bottom))
    return cropped_image

if __name__ == "__main__":
    prompt = "An animated castle with clouds"
    num_inference_steps = 28
    guidance_scale = 7.5
    seed = 42
    generateGif(prompt, num_inference_steps, guidance_scale, seed)